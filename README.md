IHC
Gem personalizado
Basado en el cÃ³digo que has subido (React + Vite) y el documento de teorÃ­a de HCI (Document 27.pdf), tu proyecto es un excelente ejemplo de DiseÃ±o Inclusivo y Multimodalidad.

El README debe resaltar no solo cÃ³mo correr el cÃ³digo, sino por quÃ© tomaste esas decisiones de diseÃ±o (justificaciÃ³n teÃ³rica).

AquÃ­ tienes una estructura completa y profesional sugerida para tu README.md. Puedes copiar y pegar esto directamente o adaptarlo.

ğŸš— Lookism - Movilidad Accesible e Inclusiva
Lookism es una prueba de concepto de una aplicaciÃ³n de transporte (tipo Uber/DiDi) diseÃ±ada especÃ­ficamente bajo principios de InteracciÃ³n Humano-Computadora (HCI) para personas con discapacidad visual (Ceguera total y Baja visiÃ³n).

El proyecto implementa interfaces adaptativas, retroalimentaciÃ³n multimodal (audio, hÃ¡ptica y visual) y flujos de navegaciÃ³n simplificados.

ğŸŒŸ CaracterÃ­sticas Principales de Accesibilidad
El sistema cuenta con tres modos de operaciÃ³n (AccessibilityContext.jsx):

1. Modo Ceguera Total (Blind Mode)
Interfaz Invisible/Simplificada: Elimina distracciones visuales, prioriza grandes Ã¡reas tÃ¡ctiles.

Screen Reader Nativo: ImplementaciÃ³n de SpeechSynthesis para lectura automÃ¡tica de estados y alertas sin depender del lector del sistema operativo.

Feedback Auditivo: Anuncios de voz para cambios de ruta, llegada del conductor y errores.

2. Modo Baja VisiÃ³n (Low Vision)
Alto Contraste: Esquema de colores amarillo sobre negro (inspirado en estÃ¡ndares de accesibilidad web).

TipografÃ­a ElÃ¡stica: Uso de unidades rem y calc() en CSS para escalar toda la interfaz sin romper el diseÃ±o (--font-scale).

Bordes Claros: Elementos interactivos con bordes gruesos y colores neÃ³n para facilitar la identificaciÃ³n.

3. InteracciÃ³n Multimodal (IMM)
Comandos de Voz: IntegraciÃ³n de API de reconocimiento de voz para dictar destinos.

RetroalimentaciÃ³n HÃ¡ptica: Uso de navigator.vibrate para confirmar acciones (ej. al reservar un viaje o llegada del conductor).

DiseÃ±o ElÃ¡stico: Botones y contenedores que crecen fÃ­sicamente si el texto aumenta, evitando solapamientos.

ğŸ› ï¸ TecnologÃ­as Utilizadas
Frontend: React 18 + Vite

Enrutamiento: React Router Dom 6

Estado Global: React Context API (para AutenticaciÃ³n, Accesibilidad y Lector de Pantalla).

Web APIs:

Web Speech API (Synthesis & Recognition) para voz.

Vibration API para feedback tÃ¡ctil.

LocalStorage para persistencia de preferencias y usuario.

ğŸ“‹ JustificaciÃ³n HCI (InteracciÃ³n Persona-Ordenador)
Este proyecto aplica principios teÃ³ricos clave (basado en Document 27.pdf):

Multimodalidad: No depende de un solo canal sensorial. Si el usuario no puede ver, puede escuchar y tocar.

PrevenciÃ³n de Errores:

ValidaciÃ³n de formularios en tiempo real.

ConfirmaciÃ³n de acciones crÃ­ticas (ej. BotÃ³n de PÃ¡nico o Cancelar Viaje).

Visibilidad del Estado del Sistema:

Feedback constante: "Buscando conductor...", "Conductor ha llegado".

Uso de aria-live y roles semÃ¡nticos para lectores de pantalla externos.

DiseÃ±o Universal: La arquitectura CSS permite que la misma base de cÃ³digo sirva a usuarios estÃ¡ndar y usuarios con discapacidades severas simplemente cambiando las variables de contexto.

ğŸš€ InstalaciÃ³n y EjecuciÃ³n
Sigue estos pasos para probar el proyecto localmente:

Clonar el repositorio:

Bash
git clone <URL_DEL_REPOSITORIO>
cd proyecto-lina-login
Instalar dependencias:

Bash
npm install
Correr el servidor de desarrollo:

Bash
npm run dev
Abrir en el navegador: Visita http://localhost:5173 (o el puerto que indique la terminal).

Nota: Para probar las funciones de Voz y VibraciÃ³n, se recomienda usar Google Chrome o Edge. La vibraciÃ³n solo funcionarÃ¡ en dispositivos mÃ³viles (Android) o emuladores que soporten hardware tÃ¡ctil.

ğŸ§ª GuÃ­a de Pruebas (User Journey)
Para evaluar la accesibilidad, sigue este flujo:

Login: Ingresa con cualquier correo (ej. test@correo.com).

Onboarding: Selecciona tu modo de visiÃ³n (ej. "Discapacidad Visual"). EscucharÃ¡s la confirmaciÃ³n de voz.

Home: Nota cÃ³mo la interfaz cambia a alto contraste. Usa el botÃ³n flotante de micrÃ³fono.

BÃºsqueda: Escribe o dicta un destino. El sistema autocompletarÃ¡ lugares simulados.

SelecciÃ³n de Viaje: Escoge "LKS Pets" (opciÃ³n para perros guÃ­a).

Estado del Viaje: Espera 5 segundos. El sistema vibrarÃ¡ y anunciarÃ¡ que el conductor ha llegado.

PÃ¡nico: Prueba el botÃ³n SOS para ver el modal de emergencia accesible.

ğŸ“‚ Estructura del Proyecto
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ Interaction/    # Controles de voz, lector y tamaÃ±o de texto
â”‚   â””â”€â”€ Layout/         # Sidebar y estructuras base
â”œâ”€â”€ context/
â”‚   â”œâ”€â”€ AccessibilityContext.jsx  # LÃ³gica de modos (Ciego/Baja VisiÃ³n)
â”‚   â””â”€â”€ ScreenReaderContext.jsx   # Motor de sÃ­ntesis de voz
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ Home.jsx        # Pantalla principal con accesos rÃ¡pidos
â”‚   â”œâ”€â”€ TripStatus.jsx  # SimulaciÃ³n de viaje en tiempo real
â”‚   â””â”€â”€ ...
â”œâ”€â”€ utils/              # Mock de almacenamiento y autenticaciÃ³n
â””â”€â”€ App.jsx             # ConfiguraciÃ³n de rutas protegidas
âš ï¸ Estado Actual y Limitaciones
Este proyecto es un prototipo acadÃ©mico (Mock Data). No conecta con conductores reales ni procesa pagos reales.

La API de reconocimiento de voz requiere conexiÃ³n a internet y permisos del navegador.

La persistencia de datos es local (localStorage), por lo que se borrarÃ¡ si limpias el navegador.

